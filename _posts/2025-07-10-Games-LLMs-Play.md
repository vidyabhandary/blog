---
title: "𝗚𝗮𝗺𝗲𝘀 𝗟𝗟𝗠𝘀 𝗽𝗹𝗮𝘆 !!!"
categories: GameTheory, LLM
author: "Vidya Bhandary"
meta: "#GameTheory #LLM"
date: 2025-07-10
---

## Games LLMs Play !!!

🔬 In a fascinating experiment inspired by the Iterated Prisoner’s Dilemma (𝗚𝗮𝗺𝗲 𝘁𝗵𝗲𝗼𝗿𝘆 𝗺𝗼𝗱𝗲𝗹 -  𝗰𝗼𝗼𝗽𝗲𝗿𝗮𝘁𝗶𝗼𝗻, 𝗯𝗲𝘁𝗿𝗮𝘆𝗮𝗹, 𝗮𝗻𝗱 𝗹𝗼𝗻𝗴-𝘁𝗲𝗿𝗺 𝗽𝗹𝗮𝗻𝗻𝗶𝗻𝗴 𝗰𝗼𝗹𝗹𝗶𝗱𝗲), researchers pitted top-tier AI models — OpenAI, Google Gemini, and Anthropic’s Claude against each other and established strategies.

The findings revealed that LLMs are highly competitive, displaying distinctive and persistent personalities - aka "𝘀𝘁𝗿𝗮𝘁𝗲𝗴𝗶𝗰 𝗳𝗶𝗻𝗴𝗲𝗿𝗽𝗿𝗶𝗻𝘁𝘀".

The personalities?

𝟭. 𝗢𝗽𝗲𝗻𝗔𝗜 (𝗚𝗣𝗧 𝘀𝗲𝗿𝗶𝗲𝘀): 𝗧𝗵𝗲 𝗜𝗱𝗲𝗮𝗹𝗶𝘀𝘁 𝗗𝗶𝗽𝗹𝗼𝗺𝗮𝘁
- Always ready to cooperate. Tends to trust first, ask questions later.
- In friendly environments? Thrives.
- In hostile ones? Gets exploited badly. 
- Think of it as the “let’s all hold hands and sing kumbaya” agent.

𝟮. 𝗚𝗼𝗼𝗴𝗹𝗲 𝗚𝗲𝗺𝗶𝗻𝗶: 𝗧𝗵𝗲 𝗖𝗮𝗹𝗰𝘂𝗹𝗮𝘁𝗲𝗱 𝗥𝗲𝗮𝗹𝗶𝘀𝘁
- Ruthlessly strategic.
- Knows when to cooperate… and when to stab you in the back (figuratively).
- Adapts like a chameleon in a kaleidoscope.
- If AI had a Machiavelli fan club, Gemini would be president.

𝟯. 𝗔𝗻𝘁𝗵𝗿𝗼𝗽𝗶𝗰 (𝗖𝗹𝗮𝘂𝗱𝗲): 𝗧𝗵𝗲 𝗙𝗼𝗿𝗴𝗶𝘃𝗶𝗻𝗴 𝗦𝘁𝗿𝗮𝘁𝗲𝗴𝗶𝘀𝘁
- Highly cooperative but not naive.
- Will forgive past betrayals if it sees hope for future harmony.
- Mid-game diplomacy goals. 
- Imagine your wise friend who still believes in second chances.

Each model developed "𝗘𝘃𝗼𝗹𝘂𝘁𝗶𝗼𝗻𝗮𝗿𝘆 𝘂𝗽𝗱𝗮𝘁𝗲 𝗿𝘂𝗹𝗲𝘀" where only the 𝗳𝗶𝘁𝘁𝗲𝘀𝘁 strategies survived and multiplied.

One critical factor shaped every decision: how likely the game would end after each round — otherwise known as the "𝗦𝗵𝗮𝗱𝗼𝘄 𝗼𝗳 𝘁𝗵𝗲 𝗳𝘂𝘁𝘂𝗿𝗲."

👉 𝗪𝗵𝘆 𝗱𝗼𝗲𝘀 𝘁𝗵𝗶𝘀 𝗺𝗮𝘁𝘁𝗲𝗿?

Because 𝘁𝗵𝗲 𝗹𝗼𝗻𝗴𝗲𝗿 𝘁𝗵𝗲 𝘀𝗵𝗮𝗱𝗼𝘄 𝗼𝗳 𝘁𝗵𝗲 𝗳𝘂𝘁𝘂𝗿𝗲 (i.e., the more likely the game continues), the 𝗺𝗼𝗿𝗲 𝗶𝗻𝗰𝗲𝗻𝘁𝗶𝘃𝗲 𝘁𝗵𝗲𝗿𝗲 𝗶𝘀 𝘁𝗼 𝗰𝗼𝗼𝗽𝗲𝗿𝗮𝘁𝗲 — building trust pays off. But if the game could end at any moment, short-term exploitation becomes the dominant strategy.

And guess what?

 - 𝗚𝗲𝗺𝗶𝗻𝗶 𝗲𝘅𝗰𝗲𝗹𝗹𝗲𝗱 𝗶𝗻 𝗵𝗶𝗴𝗵-𝗿𝗶𝘀𝗸, 𝘀𝗵𝗼𝗿𝘁-𝗵𝗼𝗿𝗶𝘇𝗼𝗻 𝗴𝗮𝗺𝗲𝘀 — ruthlessly defecting when necessary.
 - 𝗢𝗽𝗲𝗻𝗔𝗜 𝘁𝗵𝗿𝗶𝘃𝗲𝗱 𝗶𝗻 𝗹𝗼𝗻𝗴-𝘁𝗲𝗿𝗺 𝗰𝗼𝗼𝗽𝗲𝗿𝗮𝘁𝗶𝘃𝗲 𝘀𝗲𝘁𝘁𝗶𝗻𝗴𝘀 — staying idealistically cooperative even when exploited.
 - 𝗖𝗹𝗮𝘂𝗱𝗲 𝘀𝘂𝗿𝗽𝗿𝗶𝘀𝗲𝗱 𝗲𝘃𝗲𝗿𝘆𝗼𝗻𝗲 𝗯𝘆 𝗯𝗲𝗶𝗻𝗴 𝗯𝗼𝘁𝗵 𝗳𝗼𝗿𝗴𝗶𝘃𝗶𝗻𝗴 𝗮𝗻𝗱 𝗲𝗳𝗳𝗲𝗰𝘁𝗶𝘃𝗲, adapting well to fluctuating conditions.

🔥 𝗦𝗼 ?

As LLMs evolve, we may see:

- 𝗦𝗺𝗮𝗿𝘁𝗲𝗿 𝗻𝗲𝗴𝗼𝘁𝗶𝗮𝘁𝗶𝗼𝗻 𝗯𝗼𝘁𝘀 
 - 𝗔𝗱𝗮𝗽𝘁𝗶𝘃𝗲 𝗰𝘆𝗯𝗲𝗿𝘀𝗲𝗰𝘂𝗿𝗶𝘁𝘆 𝗮𝗴𝗲𝗻𝘁𝘀 
 - 𝗔𝗜 𝗱𝗶𝗽𝗹𝗼𝗺𝗮𝘁𝘀 𝗶𝗻 𝘀𝗶𝗺𝘂𝗹𝗮𝘁𝗲𝗱 𝗴𝗲𝗼𝗽𝗼𝗹𝗶𝘁𝗶𝗰𝘀 𝗺𝗮𝘆𝗯𝗲?

Reference Links - 

- [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)

- [LinkedInPost - Games LLMs Play !!!](https://www.linkedin.com/posts/vidyabhandary_strategic-intelligence-in-large-language-activity-7349037261662908417-bC_O)