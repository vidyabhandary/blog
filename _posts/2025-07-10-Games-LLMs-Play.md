---
title: "ğ—šğ—®ğ—ºğ—²ğ˜€ ğ—Ÿğ—Ÿğ— ğ˜€ ğ—½ğ—¹ğ—®ğ˜† !!!"
categories: GameTheory, LLM
author: "Vidya Bhandary"
meta: "#GameTheory #LLM"
date: 2025-07-10
---

## Games LLMs Play !!!

ğŸ”¬ In a fascinating experiment inspired by the Iterated Prisonerâ€™s Dilemma (ğ—šğ—®ğ—ºğ—² ğ˜ğ—µğ—²ğ—¼ğ—¿ğ˜† ğ—ºğ—¼ğ—±ğ—²ğ—¹ -  ğ—°ğ—¼ğ—¼ğ—½ğ—²ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—», ğ—¯ğ—²ğ˜ğ—¿ğ—®ğ˜†ğ—®ğ—¹, ğ—®ğ—»ğ—± ğ—¹ğ—¼ğ—»ğ—´-ğ˜ğ—²ğ—¿ğ—º ğ—½ğ—¹ğ—®ğ—»ğ—»ğ—¶ğ—»ğ—´ ğ—°ğ—¼ğ—¹ğ—¹ğ—¶ğ—±ğ—²), researchers pitted top-tier AI models â€” OpenAI, Google Gemini, and Anthropicâ€™s Claude against each other and established strategies.

The findings revealed that LLMs are highly competitive, displaying distinctive and persistent personalities - aka "ğ˜€ğ˜ğ—¿ğ—®ğ˜ğ—²ğ—´ğ—¶ğ—° ğ—³ğ—¶ğ—»ğ—´ğ—²ğ—¿ğ—½ğ—¿ğ—¶ğ—»ğ˜ğ˜€".

The personalities?

ğŸ­. ğ—¢ğ—½ğ—²ğ—»ğ—”ğ—œ (ğ—šğ—£ğ—§ ğ˜€ğ—²ğ—¿ğ—¶ğ—²ğ˜€): ğ—§ğ—µğ—² ğ—œğ—±ğ—²ğ—®ğ—¹ğ—¶ğ˜€ğ˜ ğ——ğ—¶ğ—½ğ—¹ğ—¼ğ—ºğ—®ğ˜
- Always ready to cooperate. Tends to trust first, ask questions later.
- In friendly environments? Thrives.
- In hostile ones? Gets exploited badly. 
- Think of it as the â€œletâ€™s all hold hands and sing kumbayaâ€ agent.

ğŸ®. ğ—šğ—¼ğ—¼ğ—´ğ—¹ğ—² ğ—šğ—²ğ—ºğ—¶ğ—»ğ—¶: ğ—§ğ—µğ—² ğ—–ğ—®ğ—¹ğ—°ğ˜‚ğ—¹ğ—®ğ˜ğ—²ğ—± ğ—¥ğ—²ğ—®ğ—¹ğ—¶ğ˜€ğ˜
- Ruthlessly strategic.
- Knows when to cooperateâ€¦ and when to stab you in the back (figuratively).
- Adapts like a chameleon in a kaleidoscope.
- If AI had a Machiavelli fan club, Gemini would be president.

ğŸ¯. ğ—”ğ—»ğ˜ğ—µğ—¿ğ—¼ğ—½ğ—¶ğ—° (ğ—–ğ—¹ğ—®ğ˜‚ğ—±ğ—²): ğ—§ğ—µğ—² ğ—™ğ—¼ğ—¿ğ—´ğ—¶ğ˜ƒğ—¶ğ—»ğ—´ ğ—¦ğ˜ğ—¿ğ—®ğ˜ğ—²ğ—´ğ—¶ğ˜€ğ˜
- Highly cooperative but not naive.
- Will forgive past betrayals if it sees hope for future harmony.
- Mid-game diplomacy goals. 
- Imagine your wise friend who still believes in second chances.

Each model developed "ğ—˜ğ˜ƒğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¿ğ˜† ğ˜‚ğ—½ğ—±ğ—®ğ˜ğ—² ğ—¿ğ˜‚ğ—¹ğ—²ğ˜€" where only the ğ—³ğ—¶ğ˜ğ˜ğ—²ğ˜€ğ˜ strategies survived and multiplied.

One critical factor shaped every decision: how likely the game would end after each round â€” otherwise known as the "ğ—¦ğ—µğ—®ğ—±ğ—¼ğ˜„ ğ—¼ğ—³ ğ˜ğ—µğ—² ğ—³ğ˜‚ğ˜ğ˜‚ğ—¿ğ—²."

ğŸ‘‰ ğ—ªğ—µğ˜† ğ—±ğ—¼ğ—²ğ˜€ ğ˜ğ—µğ—¶ğ˜€ ğ—ºğ—®ğ˜ğ˜ğ—²ğ—¿?

Because ğ˜ğ—µğ—² ğ—¹ğ—¼ğ—»ğ—´ğ—²ğ—¿ ğ˜ğ—µğ—² ğ˜€ğ—µğ—®ğ—±ğ—¼ğ˜„ ğ—¼ğ—³ ğ˜ğ—µğ—² ğ—³ğ˜‚ğ˜ğ˜‚ğ—¿ğ—² (i.e., the more likely the game continues), the ğ—ºğ—¼ğ—¿ğ—² ğ—¶ğ—»ğ—°ğ—²ğ—»ğ˜ğ—¶ğ˜ƒğ—² ğ˜ğ—µğ—²ğ—¿ğ—² ğ—¶ğ˜€ ğ˜ğ—¼ ğ—°ğ—¼ğ—¼ğ—½ğ—²ğ—¿ğ—®ğ˜ğ—² â€” building trust pays off. But if the game could end at any moment, short-term exploitation becomes the dominant strategy.

And guess what?

 - ğ—šğ—²ğ—ºğ—¶ğ—»ğ—¶ ğ—²ğ˜…ğ—°ğ—²ğ—¹ğ—¹ğ—²ğ—± ğ—¶ğ—» ğ—µğ—¶ğ—´ğ—µ-ğ—¿ğ—¶ğ˜€ğ—¸, ğ˜€ğ—µğ—¼ğ—¿ğ˜-ğ—µğ—¼ğ—¿ğ—¶ğ˜‡ğ—¼ğ—» ğ—´ğ—®ğ—ºğ—²ğ˜€ â€” ruthlessly defecting when necessary.
 - ğ—¢ğ—½ğ—²ğ—»ğ—”ğ—œ ğ˜ğ—µğ—¿ğ—¶ğ˜ƒğ—²ğ—± ğ—¶ğ—» ğ—¹ğ—¼ğ—»ğ—´-ğ˜ğ—²ğ—¿ğ—º ğ—°ğ—¼ğ—¼ğ—½ğ—²ğ—¿ğ—®ğ˜ğ—¶ğ˜ƒğ—² ğ˜€ğ—²ğ˜ğ˜ğ—¶ğ—»ğ—´ğ˜€ â€” staying idealistically cooperative even when exploited.
 - ğ—–ğ—¹ğ—®ğ˜‚ğ—±ğ—² ğ˜€ğ˜‚ğ—¿ğ—½ğ—¿ğ—¶ğ˜€ğ—²ğ—± ğ—²ğ˜ƒğ—²ğ—¿ğ˜†ğ—¼ğ—»ğ—² ğ—¯ğ˜† ğ—¯ğ—²ğ—¶ğ—»ğ—´ ğ—¯ğ—¼ğ˜ğ—µ ğ—³ğ—¼ğ—¿ğ—´ğ—¶ğ˜ƒğ—¶ğ—»ğ—´ ğ—®ğ—»ğ—± ğ—²ğ—³ğ—³ğ—²ğ—°ğ˜ğ—¶ğ˜ƒğ—², adapting well to fluctuating conditions.

ğŸ”¥ ğ—¦ğ—¼ ?

As LLMs evolve, we may see:

- ğ—¦ğ—ºğ—®ğ—¿ğ˜ğ—²ğ—¿ ğ—»ğ—²ğ—´ğ—¼ğ˜ğ—¶ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—¯ğ—¼ğ˜ğ˜€ 
 - ğ—”ğ—±ğ—®ğ—½ğ˜ğ—¶ğ˜ƒğ—² ğ—°ğ˜†ğ—¯ğ—²ğ—¿ğ˜€ğ—²ğ—°ğ˜‚ğ—¿ğ—¶ğ˜ğ˜† ğ—®ğ—´ğ—²ğ—»ğ˜ğ˜€ 
 - ğ—”ğ—œ ğ—±ğ—¶ğ—½ğ—¹ğ—¼ğ—ºğ—®ğ˜ğ˜€ ğ—¶ğ—» ğ˜€ğ—¶ğ—ºğ˜‚ğ—¹ğ—®ğ˜ğ—²ğ—± ğ—´ğ—²ğ—¼ğ—½ğ—¼ğ—¹ğ—¶ğ˜ğ—¶ğ—°ğ˜€ ğ—ºğ—®ğ˜†ğ—¯ğ—²?

Reference Links - 

- [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)

- [LinkedInPost - Games LLMs Play !!!](https://www.linkedin.com/posts/vidyabhandary_strategic-intelligence-in-large-language-activity-7349037261662908417-bC_O)