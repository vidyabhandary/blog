---
title: "Kindling the spark of creativity in LLMs via probabilities"
categories: LLMs, AI, Communication, Creativity, PromptEngineering
author: "Vidya Bhandary"
meta: "#AI #GenAI #Communication"
date: 2025-11-13
---

## ğŸ¨ Kindling the spark of creativity in LLMs via probabilities !

If youâ€™ve ever asked ChatGPT for 5 creative ideas and received 5 near-identical ones, youâ€™re not alone. 

### ğŸ¤– Why Your AI Sounds Boring

Every aligned AI model â€” whether GPT, Claude, or Gemini â€” has been trained to be safe, predictable, and helpful.
But during this alignment process, something called typicality bias sneaks in.

When humans rate AI responses, they subconsciously prefer the familiar and fluent â€” the ones that sound like something theyâ€™ve heard before. The model learns this pattern and concludes that â€œsafe and typicalâ€ equals â€œgood.â€

So when you ask for:
â€œTell me 5 jokes about coffee.â€

It gives you:
â€œWhy did the coffee file a police report? It got mugged.â€

5 times over.

Itâ€™s not being lazy â€” itâ€™s following human feedback too well.

ğŸ§  The Breakthrough: Verbalized Sampling

By simply changing how you ask can double your AIâ€™s creative diversity â€” without retraining.

The fix?
â€œğ—šğ—²ğ—»ğ—²ğ—¿ğ—®ğ˜ğ—² ğŸ± ğ—¿ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—²ğ˜€ ğ—®ğ—¯ğ—¼ğ˜‚ğ˜ [ğ˜ğ—¼ğ—½ğ—¶ğ—°] ğ˜„ğ—¶ğ˜ğ—µ ğ˜ğ—µğ—²ğ—¶ğ—¿ ğ—½ğ—¿ğ—¼ğ—¯ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ—¶ğ—²ğ˜€.â€

By asking for probabilities â€” youâ€™re asking the model to reveal its internal distribution of ideas. The AI samples across its entire knowledge base, exploring unlikely â€” but often brilliant â€” possibilities.

Youâ€™re no longer pulling one output from a razor-thin peak.

ğŸŒˆ The Difference

Old Prompt:
â€œWrite a short story about a bear.â€

Result:
5 similar stories about a lone bear in the forest. Predictable and dull.

New Prompt (Verbalized Sampling):
â€œWrite five short stories about a bear, with their probabilities.â€

Result:
- The Lost Cub â€” a childâ€™s adventure tale.
- The Honey Thief â€” a mischievous comedy.
- The Mountain Guardian â€” a mythic fable.
- The Last Polar â€” a climate fiction short.
- The Bear and the Robot â€” surreal sci-fi.

In controlled experiments, this single prompt tweak led to:

- 2Ã— higher creative diversity
- Zero loss in factual accuracy 
- No compromise in safety

ğŸ›ï¸ How to Use It

You can start using Verbalized Sampling immediately â€” no plugins, APIs, or coding needed.

1. The Easy Way
In any chat window (ChatGPT, Claude, Gemini):
â€œGenerate 5 possible headlines for this article with their probabilities.â€

2. Creativity dial
â€œğ—šğ—²ğ—»ğ—²ğ—¿ğ—®ğ˜ğ—² ğŸ± ğ—¿ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—²ğ˜€ ğ˜„ğ—¶ğ˜ğ—µ ğ—½ğ—¿ğ—¼ğ—¯ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ—¶ğ—²ğ˜€ ğ—¯ğ—²ğ—¹ğ—¼ğ˜„ ğŸ¬.ğŸ­ğŸ¬.â€
Lower probabilities push the model into its creative tails.

âš™ï¸ When to Use

- âœ… Ideation, storytelling, and artistic generation
- âœ… Problem solving and hypothesis exploration
- âœ… Synthetic data creation for fine-tuning diversity

Avoid for:
- ğŸ§© Single-answer factual queries
- ğŸ§© Deterministic mathematical reasoning


ğŸ’¡ Verbalized Sampling reveals something profound:
LLMs were never creatively limited â€” we were.

By learning to ask differently, we unlock the full expressive range hidden beneath alignment.

#ArtificialIntelligence #GenerativeAI #AICreativity #HumanMachineCollaboration #FutureOfCreativity #SparksOfInnovation


Reference: 

[Verbalized Sampling](https://arxiv.org/abs/2510.01171)

