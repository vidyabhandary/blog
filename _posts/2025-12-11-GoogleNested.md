---
title: "Google's Nested Learning"
categories: LLMs, AI, NestedLearning, Research, AgenticAI
author: "Vidya Bhandary"
meta: "#AI #LLM #AgenticAI"
date: 2025-12-11
---

ğŸ”¥ ğ—šğ—¼ğ—¼ğ—´ğ—¹ğ—²'ğ˜€ ğ—¡ğ—²ğ˜€ğ˜ğ—²ğ—± ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´: ğ—›ğ—¼ğ˜„ ğ—¦ğ—²ğ—¹ğ—³-ğ— ğ—¼ğ—±ğ—¶ğ—³ğ˜†ğ—¶ğ—»ğ—´ ğ—§ğ—¶ğ˜ğ—®ğ—»ğ˜€ ğ— ğ—²ğ—¿ğ—´ğ—² ğ—¢ğ—½ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—®ğ—»ğ—± ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†

![](https://raw.githubusercontent.com/vidyabhandary/blog/refs/heads/master/images/HOPE.png)

AI has a memory problem.
Your brain can learn something new today without wiping yesterday.
AI? It forgets instantly. ğ—–ğ—®ğ˜ğ—®ğ˜€ğ˜ğ—¿ğ—¼ğ—½ğ—µğ—¶ğ—° ğ—³ğ—¼ğ—¿ğ—´ğ—²ğ˜ğ˜ğ—¶ğ—»ğ—´ is its default setting.

For years our fix was â€œmake it bigger.â€
More layers. More parameters. More GPUs.

Googleâ€™s latest research says:
ğ—ªğ—²â€™ğ˜ƒğ—² ğ—¯ğ—²ğ—²ğ—» ğ˜€ğ—°ğ—®ğ—¹ğ—¶ğ—»ğ—´ ğ˜ğ—µğ—² ğ˜„ğ—¿ğ—¼ğ—»ğ—´ ğ—±ğ—¶ğ—ºğ—²ğ—»ğ˜€ğ—¶ğ—¼ğ—».

ğŸ§  ğ—§ğ—µğ—² ğ—•ğ—¿ğ—®ğ—¶ğ—» ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ˜€ ğ—Ÿğ—¶ğ—¸ğ—² ğ—®ğ—» ğ—¢ğ—¿ğ—°ğ—µğ—²ğ˜€ğ˜ğ—¿ğ—® â€” Not a Metronome

Your brain runs multiple learning tempos at once:

- ğ—šğ—®ğ—ºğ—ºğ—®: fast, reactive
- ğ—•ğ—²ğ˜ğ—®: active thinking
- ğ—§ğ—µğ—²ğ˜ğ—®/ğ——ğ—²ğ—¹ğ˜ğ—®: slow, deep storage

AI today forces every â€œinstrumentâ€ to learn at the same speedâ€¦ then shuts learning off entirely after training.

This is the ğ—¶ğ—¹ğ—¹ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» ğ—¼ğ—³ ğ—±ğ—²ğ—½ğ˜ğ—µ.

ğŸ¼ ğ—¡ğ—²ğ˜€ğ˜ğ—²ğ—± ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´: ğ—”ğ—œ ğ—ªğ—¶ğ˜ğ—µ ğ— ğ˜‚ğ—¹ğ˜ğ—¶ğ—½ğ—¹ğ—² ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—§ğ—²ğ—ºğ—½ğ—¼ğ˜€
Googleâ€™s Nested Learning reframes a model as layers of learners, each updating at its own frequency:

- ğ—™ğ—®ğ˜€ğ˜ â†’ immediate context
- ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º â†’ structural patterns
- ğ—¦ğ—¹ğ—¼ğ˜„ â†’ stable long-term memory

A multi-tempo learning system â€” just like your brain.

ğŸ’¥ ğ—§ğ—µğ—² ğ—•ğ—¿ğ—²ğ—®ğ—¸ğ˜ğ—µğ—¿ğ—¼ğ˜‚ğ—´ğ—µ ğ—œğ—»ğ˜€ğ—¶ğ—´ğ—µğ˜:
Optimizers = Memory Systems

Google shows:

- ğŸ”¹ Backprop is memory of surprise
- ğŸ”¹ Momentum is memory of gradient history
- ğŸ”¹ Adam is memory of long-term trends
- ğŸ”¹ Pre-training is massive long-term consolidation

Once you treat optimizers as memoryâ€¦
- â¡ï¸ the boundary between training and inference disappears.
- â¡ï¸ models can update ğ™¬ğ™ğ™ğ™¡ğ™š ğ™©ğ™ğ™šğ™® ğ™©ğ™ğ™ğ™£ğ™ .

Thatâ€™s the basis of Googleâ€™s new architecture.

ğŸ¹ ğ—›ğ—¢ğ—£ğ—˜ â€” The Model Designed to Never Forget

HOPE blends two memory systems:

ğŸ»ğ—§ğ—¶ğ˜ğ—®ğ—»ğ˜€ (ğ—™ğ—®ğ˜€ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†)

- ğŸ”¹ Self-modifying blocks that adapt during inference.
- ğŸ”¹ Real-time learning.

 ğŸºğ—–ğ—¼ğ—»ğ˜ğ—¶ğ—»ğ˜‚ğ˜‚ğ—º ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜† ğ—¦ğ˜†ğ˜€ğ˜ğ—²ğ—º (ğ—¦ğ—¹ğ—¼ğ˜„ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†)

- ğŸ”¹ A chain of slow-updating memory modules that donâ€™t get overwritten.
- ğŸ”¹ Long-term stability.

Together, HOPE learns in multiple tempos â€” like cognition, not computation.

 ğŸº The ğ—¥ğ—²ğ˜€ğ˜‚ğ—¹ğ˜ğ˜€? 

 Continual Learning:
- ğŸ”¹ Retains old tasks while learning new ones.

Zero catastrophic forgetting.
- ğŸ”¹ Needle-in-a-Haystack: Scored 100% where Transformers buckled under long contexts.
- ğŸ”¹ Language Modeling: Outperformed strong Transformer baselines even on standard LM tasks.

Weâ€™ve spent a decade building bigger models that forget easily.
Transformers made AI powerful.

Nested Learning could make it ğ—®ğ—¹ğ—¶ğ˜ƒğ—² â€” adaptive, continuous, memorable.
And do what your brain does naturally: ğ—¹ğ—²ğ—®ğ—¿ğ—» ğ˜ğ—¼ğ—±ğ—®ğ˜† ğ˜„ğ—¶ğ˜ğ—µğ—¼ğ˜‚ğ˜ ğ—¹ğ—¼ğ˜€ğ—¶ğ—»ğ—´ ğ˜†ğ—²ğ˜€ğ˜ğ—²ğ—¿ğ—±ğ—®ğ˜†.

This isnâ€™t a drop-in replacement for Transformers â€”
ğ—¶ğ˜â€™ğ˜€ ğ—® ğ—±ğ—¶ğ—¿ğ—²ğ—°ğ˜ğ—¶ğ—¼ğ—», ğ—»ğ—¼ğ˜ ğ—® ğ—±ğ—²ğ˜€ğ˜ğ—¶ğ—»ğ—®ğ˜ğ—¶ğ—¼ğ—» (ğ˜†ğ—²ğ˜).

Reference: 

[Google Research: Introducing Nested Learning: A new ML paradigm for continual learning](https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/)

